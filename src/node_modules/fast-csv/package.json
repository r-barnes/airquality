{
  "name": "fast-csv",
  "version": "0.4.0",
  "description": "CSV parser and writer",
  "main": "index.js",
  "scripts": {
    "test": "grunt jshint it"
  },
  "repository": {
    "type": "git",
    "url": "git@github.com:C2FO/fast-csv.git"
  },
  "keywords": [
    "csv",
    "parser",
    "fast",
    "writer",
    "csv writer",
    "CSV"
  ],
  "homepage": "http://c2fo.github.com/fast-csv/index.html",
  "author": {
    "name": "Doug Martin"
  },
  "license": "MIT",
  "devDependencies": {
    "it": "~0.2.6",
    "grunt-it": "~0.3.1",
    "grunt": "~0.4.1",
    "grunt-contrib-jshint": "~0.10.0",
    "grunt-exec": "^0.4.5"
  },
  "engines": {
    "node": ">=0.10"
  },
  "dependencies": {
    "is-extended": "0.0.10",
    "object-extended": "0.0.7",
    "extended": "0.0.6",
    "string-extended": "0.0.8"
  },
  "readme": "[![build status](https://secure.travis-ci.org/C2FO/fast-csv.png)](http://travis-ci.org/C2FO/fast-csv)\n# Fast-csv\n\nThis is a library that provides CSV parsing and formatting.\n\n**NOTE** As of v0.2.0 `fast-csv` supports multi-line values.\n\n## Installation\n\n`npm install fast-csv`\n\n## Usage\n\n### Parsing\n\nAll methods accept the following `options`\n\n* `objectMode=true`: Ensure that `data` events have an object emitted rather than the stringified version set to false to have a stringified buffer.\n* `headers=false`: Ste to true if you expect the first line of your `CSV` to contain headers, alternatly you can specify an array of headers to use.\n* `ignoreEmpty=false`: If you wish to ignore empty rows.\n* `delimiter=','`: If your data uses an alternate delimiter such as `;` or `\\t`.\n   * **NOTE** When specifying an alternate `delimiter` you may only pass in a single character delimiter\n* `quote='\"'`: The character to use to escape values that contain a delimiter.\n* `escape='\"'`: The character to use when escaping a value that is `quoted` and contains a `quote` character.\n    * `i.e`: 'First,\"Name\"' => '\"First,\"\"name\"\"\"'\n* The following are options for parsing only.\n  * `trim=false`: If you want to trim all values parsed set to true.\n  * `rtrim=false`: If you want to right trim all values parsed set to true.\n  * `ltrim=false`: If you want to left trim all values parsed set to true.\n\n\n**events**\n\n* `record`: Emitted when a record is parsed.\n* `data-invalid`: Emitted if there was invalid row encounted, **only emitted if the `validate` function is used**.\n* `data`: Emitted with the object or `stringified` version if the `objectMode` is set to `false`.\n\n**([options])**\n\nIf you use `fast-csv` as a function it returns a transform stream that can be piped into.\n\n```javascript\nvar stream = fs.createReadStream(\"my.csv\");\n\nvar csvStream = csv()\n .on(\"record\", function(data){\n     console.log(data):\n })\n .on(\"end\", function(){\n     console.log(\"done\");\n });\n\nstream.pipe(csvStream);\n```\n\n**`.fromPath(path[, options])`**\n\nThis method parses a file from the specified path.\n\n```javascript\nvar csv = require(\"fast-csv\");\n\ncsv\n .fromPath(\"my.csv\")\n .on(\"record\", function(data){\n     console.log(data):\n })\n .on(\"end\", function(){\n     console.log(\"done\");\n });\n```\n\n**`.fromString(string[, options])`**\n\nThis method parses a string\n\n```javascript\nvar csv = require(\"fast-csv\");\n\nvar CSV_STRING = 'a,b\\n' +\n                 'a1,b1\\n' +\n                 'a2,b2\\n';\n\ncsv\n .fromPath(CSV_STRING, {headers: true})\n .on(\"record\", function(data){\n     console.log(data):\n })\n .on(\"end\", function(){\n     console.log(\"done\");\n });\n```\n\n**`.fromStream(stream[, options])`**\n\nThis accepted a readable stream to parse data from.\n\n```javascript\nvar stream = fs.createReadStream(\"my.csv\");\n\ncsv()\n .fromStream(stream)\n .on(\"record\", function(data){\n     console.log(data):\n })\n .on(\"end\", function(){\n     console.log(\"done\");\n });\n```\n\nIf you expect the first line your csv to headers you may pass a headers option in. Setting the headers option will\ncause change each row to an object rather than an array.\n\n```javascript\nvar stream = fs.createReadStream(\"my.csv\");\n\ncsv()\n .fromStream(stream, {headers : true})\n .on(\"record\", function(data){\n     console.log(data):\n })\n .on(\"end\", function(){\n     console.log(\"done\");\n });\n\n```\n\nYou may alternatively pass an array of header names which must match the order of each column in the csv, otherwise\nthe data columns will not match.\n\n```javascript\nvar stream = fs.createReadStream(\"my.csv\");\n\ncsv\n .fromStream(stream, {headers : [\"firstName\", \"lastName\", \"address\"]})\n .on(\"record\", function(data){\n     console.log(data):\n })\n .on(\"end\", function(){\n     console.log(\"done\");\n });\n\n```\n\nIf your data may include empty rows, the sort Excel might include at the end of the file for instance, you can ignore\nthese by including the `ignoreEmpty` option.\n\nAny rows consisting of nothing but empty strings and/or commas will be skipped, without emitting a 'data' or 'error' event.\n\n```javascript\nvar stream = fs.createReadStream(\"my.csv\");\n\ncsv\n .fromStream(stream, {ignoreEmpty: true})\n .on(\"record\", function(data){\n     console.log(data):\n })\n .on(\"end\", function(){\n     console.log(\"done\");\n });\n\n```\n\n### Validating\n\nYou can validate each row in the csv by providing a validate handler. If a row is invalid then a `data-invalid` event\nwill be emitted with the row and the index.\n\n```javascript\nvar stream = fs.createReadStream(\"my.csv\");\n\ncsv(\n .fromStream(stream, {headers : true})\n .validate(function(data){\n     return data.age < 50; //all persons must be under the age of 50\n })\n .on(\"data-invalid\", function(data){\n     //do something with invalid row\n })\n .on(\"record\", function(data){\n     console.log(data):\n })\n .on(\"end\", function(){\n     console.log(\"done\");\n });\n\n```\n\n### Transforming\n\nYou can transform data by providing in a transform function. What is returned from the transform function will\nbe provided to validate and emitted as a row.\n\n```javascript\nvar stream = fs.createReadStream(\"my.csv\");\n\ncsv\n .fromStream(stream)\n .transform(function(data){\n     return data.reverse(); //reverse each row.\n })\n .on(\"record\", function(data){\n     console.log(data):\n })\n .on(\"end\", function(){\n     console.log(\"done\");\n });\n\n```\n\n### Formatting\n\n`fast-csv` also allows to you to create create a `CSV` from data.\n\nFormatting accepts the same options as parsing with an additional `transform` option.\n\n* `transform(row)`: A function that accepts a row and returns a transformed one to be written.\n\n**`createWriteStream(options)`**\n\nThis is the lowest level of the write methods, it creates a stream that can be used to create a csv of unknown size and pipe to an output csv.\n\n```javascript\nvar csvStream = csv.createWriteStream({headers: true}),\n    writableStream = fs.createWriteStream(\"my.csv\");\n\nwritableStream.on(\"finish\", function(){\n  console.log(\"DONE!\");\n});\n\ncsvSream.pipe(writableStream);\ncsvStream.write({a: \"a0\", b: \"b0\"});\ncsvStream.write({a: \"a1\", b: \"b1\"});\ncsvStream.write({a: \"a2\", b: \"b2\"});\ncsvStream.write({a: \"a3\", b: \"b4\"});\ncsvStream.write({a: \"a3\", b: \"b4\"});\ncsvStream.write(null);\n```\n\nIf you wish to transform rows as writing then you can use the `.transform` method.\n\n```javascript\nvar csvStream = csv\n    .createWriteStream({headers: true})\n    .transform(function(row){\n        return {\n           A: row.a,\n           B: row.b\n        };\n    }),\n    writableStream = fs.createWriteStream(\"my.csv\");\n\nwritableStream.on(\"finish\", function(){\n  console.log(\"DONE!\");\n});\n\ncsvSream.pipe(writableStream);\ncsvStream.write({a: \"a0\", b: \"b0\"});\ncsvStream.write({a: \"a1\", b: \"b1\"});\ncsvStream.write({a: \"a2\", b: \"b2\"});\ncsvStream.write({a: \"a3\", b: \"b4\"});\ncsvStream.write({a: \"a3\", b: \"b4\"});\ncsvStream.write(null);\n```\n\n**Writing Data**\n\nEach of the following methods accept an array of values to be written, however each value must be an `array` of `array`s or `object`s.\n\n**`write(arr[, options])`**\n\nCreate a readable stream to read data from.\n\n```javascript\nvar ws = fs.createWriteStream(\"my.csv\");\ncsv\n   .write([\n       [\"a\", \"b\"],\n       [\"a1\", \"b1\"],\n       [\"a2\", \"b2\"]\n   ], {headers: true})\n   .pipe(ws);\n```\n\n```javascript\nvar ws = fs.createWriteStream(\"my.csv\");\ncsv\n   .write([\n       {a: \"a1\", b: \"b1\"},\n       {a: \"a2\", b: \"b2\"}\n   ], {headers: true})\n   .pipe(ws);\n```\n\n```javascript\nvar ws = fs.createWriteStream(\"my.csv\");\ncsv\n   .write([\n       {a: \"a1\", b: \"b1\"},\n       {a: \"a2\", b: \"b2\"}\n   ], {\n        headers: true\n        transform: function(row){\n            return {\n                A: row.a,\n                B: row.b\n            };\n        }\n   })\n   .pipe(ws);\n```\n\n\n\n**`writeToStream(stream,arr[, options])`**\n\nWrite an array of values to a `WritableStream`\n\n```javascript\ncsv\n   .writeToStream(fs.createWriteStream(\"my.csv\"), [\n       [\"a\", \"b\"],\n       [\"a1\", \"b1\"],\n       [\"a2\", \"b2\"]\n   ], {headers: true});\n```\n\n```javascript\ncsv\n   .writeToStream(fs.createWriteStream(\"my.csv\"), [\n       {a: \"a1\", b: \"b1\"},\n       {a: \"a2\", b: \"b2\"}\n   ], {headers: true})\n   .pipe(ws);\n```\n\n```javascript\ncsv\n   .writeToStream(fs.createWriteStream(\"my.csv\"), [\n       {a: \"a1\", b: \"b1\"},\n       {a: \"a2\", b: \"b2\"}\n   ], {\n        headers: true,\n        transform: function(row){\n            return {\n                A: row.a,\n                B: row.b\n            };\n        }\n   })\n   .pipe(ws);\n```\n\n**`writeToPath(arr[, options])`**\n\nWrite an array of values to the specified path\n\n```javascript\ncsv\n   .writeToPath(\"my.csv\", [\n       [\"a\", \"b\"],\n       [\"a1\", \"b1\"],\n       [\"a2\", \"b2\"]\n   ], {headers: true})\n   .on(\"finish\", function(){\n       console.log(\"done!\");\n   });\n```\n\n```javascript\ncsv\n   .writeToStream(\"my.csv\", [\n       {a: \"a1\", b: \"b1\"},\n       {a: \"a2\", b: \"b2\"}\n   ], {headers: true})\n   .on(\"finish\", function(){\n      console.log(\"done!\");\n   });\n```\n\n```javascript\ncsv\n   .writeToStream(\"my.csv\", [\n       {a: \"a1\", b: \"b1\"},\n       {a: \"a2\", b: \"b2\"}\n   ], {\n        headers: true,\n        transform: function(row){\n            return {\n                A: row.a,\n                B: row.b\n            };\n        }\n   })\n   .on(\"finish\", function(){\n      console.log(\"done!\");\n   });\n```\n\n**`writeToString(arr[, options])`**\n\n```javascript\ncsv.writeToString([\n   [\"a\", \"b\"],\n   [\"a1\", \"b1\"],\n   [\"a2\", \"b2\"]\n], {headers: true}); //\"a,b\\na1,b1\\na2,b2\\n\"\n```\n\n```javascript\ncsv.writeToString([\n   {a: \"a1\", b: \"b1\"},\n   {a: \"a2\", b: \"b2\"}\n], {headers: true}); //\"a,b\\na1,b1\\na2,b2\\n\"\n```\n\n```javascript\ncsv.writeToString([\n   {a: \"a1\", b: \"b1\"},\n   {a: \"a2\", b: \"b2\"}\n], {\n        headers: true,\n        transform: function(row){\n            return {\n                A: row.a,\n                B: row.b\n            };\n        }\n   }); //\"a,b\\na1,b1\\na2,b2\\n\"\n```\n\n## Piping from Parser to Writer\n\nYou can use `fast-csv` to pipe the output from a parsed CSV to a transformed CSV by setting the parser to `objectMode` and using `createWriteStream`.\n\n```javascript\ncsv\n   .fromPath(\"in.csv\", {headers: true})\n   .pipe(csv.createWriteStream({headers: true}))\n   .pipe(fs.createWriteStream(\"out.csv\", {encoding: \"utf8\"}));\n```\n\nWhen piping from a parser to a formatter the transforms are maintained also.\n\n\n```javascript\ncsv\n   .fromPath(\"in.csv\", {headers: true})\n   .transform(function(obj){\n        return {\n            name: obj.Name,\n            address: obj.Address,\n            emailAddress: obj.Email_Address,\n            verified: obj.Verified\n        };\n   })\n   .pipe(csv.createWriteStream({headers: true}))\n   .pipe(fs.createWriteStream(\"out.csv\", {encoding: \"utf8\"}));\n```\n\nThe output will contain formatted result from the transform function.\n\nIf you want to tranform on the formatting side\n\n\n```javascript\nvar formatStream = csv\n        .createWriteStream({headers: true})\n        .transform(function(){\n            return {\n                name: obj.Name,\n                address: obj.Address,\n                emailAddress: obj.Email_Address,\n                verified: obj.Verified\n            };\n        });  \ncsv\n   .fromPath(\"in.csv\", {headers: true})\n   .pipe(formatStream)\n   .pipe(fs.createWriteStream(\"out.csv\", {encoding: \"utf8\"}));\n```\n\n\n## Benchmarks\n\n`Parsing 20000 records AVG over 3 runs`\n\n```\nfast-csv: 198.67ms\ncsv:      525.33ms\n```\n\n`Parsing 50000 records AVG over 3 runs`\n\n```\nfast-csv: 441.33ms\ncsv:      1291ms\n```\n\n`Parsing 100000 records AVG over 3 runs`\n\n```\nfast-csv: 866ms\ncsv:      2773.33ms\n```\n\n`Parsing 1000000 records AVG over 3 runs`\n\n```\nfast-csv: 8562.67ms\ncsv:      30030.67ms\n```\n\n## License\n\nMIT <https://github.com/C2FO/fast-csv/raw/master/LICENSE>\n\n##Meta\n* Code: `git clone git://github.com/C2FO/fast-csv.git`\n* Website: <http://c2fo.com>\n* Twitter: [http://twitter.com/c2fo](http://twitter.com/c2fo) - 877.465.4045\n",
  "readmeFilename": "README.md",
  "bugs": {
    "url": "https://github.com/C2FO/fast-csv/issues"
  },
  "_id": "fast-csv@0.4.0",
  "dist": {
    "shasum": "417aec985cc422010c4e3d30492e852a62427af6"
  },
  "_from": "fast-csv@",
  "_resolved": "http://registry.npmjs.org/fast-csv/-/fast-csv-0.4.0.tgz"
}
